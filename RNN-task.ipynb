{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZhlzCJiZZcwhYGaWMYeAmVnG/j9X9jq2BqwyjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f69afb90668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 56\n"
     ]
    }
   ],
   "source": [
    "tokens = set('#'.join(names))\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "token_to_id = {name: i for i, name in enumerate(tokens)}\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "for i in range(n_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[10 43 32  3  9  3  4 15 47]\n",
      " [10 18 15 34 38 39 47 47 47]\n",
      " [10 49 38 24 54 54 24  4 47]\n",
      " [10 18 24 34 16  3  5  5  4]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation='relu')\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = tf.concat([x_t_emb, h_t], 1)\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    }
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "#loss = tf.reduce_mean(tf.reduce_sum(-answers_matrix*predictions_matrix))\n",
    "loss = tf.reduce_mean(tf.reduce_sum(-answers_matrix*tf.log(tf.clip_by_value(predictions_matrix,1e-10,1.0)), reduction_indices=[1]))\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6964b72ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Jaana\n",
      " Coidil\n",
      " aloso\n",
      " Cerota\n",
      " Vepdta\n",
      " Rane\n",
      " Nakna\n",
      " Midy\n",
      " Vobneyd\n",
      " Gulcun\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumpe\n",
      " Trumpy\n",
      " Trumphal\n",
      " Trumped\n",
      " Trumpen\n",
      " Trumporthe\n",
      " Trumpama\n",
      " Trumpa\n",
      " Trumpa\n",
      " Trumpia\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"YHlKlrxjDgJeXlf0\"\n",
    "COURSERA_EMAIL = \"nliu36@wisc.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 56)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "135bb98372f44a23809659e808cb5eef": {
     "views": [
      {
       "cell_index": 32
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
